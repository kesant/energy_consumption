{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44ee243d-f4f1-47a0-ab2f-9e45787acb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import davies_bouldin_score, silhouette_score\n",
    "\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
    "\n",
    "from itertools import product\n",
    "from energy_consumption_architecture.utils.paths import data_dir\n",
    "# from kneebow.rotor import Rotor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83862e7-6d2c-43bc-b46d-062eca7a911f",
   "metadata": {},
   "source": [
    "## Funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0bf6ccec-0c13-40d7-a009-572a45b080b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_k_selection(X, max_k=10):\n",
    "    \"\"\"\n",
    "    Calcula el número óptimo de clusters usando el índice de silueta y el método del codo.\n",
    "\n",
    "    Parámetros:\n",
    "    - X: Dataset (matriz de características).\n",
    "    - max_k: Número máximo de clusters a evaluar. Por defecto es 10.\n",
    "\n",
    "    Retorna:\n",
    "    - optimal_k: Número óptimo de clusters seleccionado.\n",
    "    \"\"\"\n",
    "\n",
    "    Sum_of_squared_distances = []\n",
    "    silhouette_scores = []\n",
    "    K_range = range(2, max_k + 1)\n",
    "\n",
    "    for k in K_range:\n",
    "        km = KMeans(n_clusters=k, random_state=42)\n",
    "        y = km.fit_predict(X)\n",
    "        Sum_of_squared_distances.append(km.inertia_)\n",
    "        silhouette_scores.append(silhouette_score(X, y))\n",
    "\n",
    "    # Determinación del número óptimo de clusters según el índice de silueta\n",
    "    optimal_k_silhouette = K_range[np.argmax(silhouette_scores)]\n",
    "\n",
    "    # Determinación del número óptimo de clusters según el método del codo\n",
    "    inertia_differences = np.diff(Sum_of_squared_distances)\n",
    "    optimal_k_elbow = K_range[np.argmin(inertia_differences) + 1]  # +1 para ajustar el índice\n",
    "\n",
    "    # Selección de un solo valor de K\n",
    "    if optimal_k_silhouette == optimal_k_elbow:\n",
    "        optimal_k = optimal_k_silhouette\n",
    "    else:\n",
    "        optimal_k = optimal_k_silhouette  # En caso de diferencia, priorizamos el índice de silueta\n",
    "\n",
    "    return optimal_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa5ba80-f86f-48d4-9f13-405b604e3852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_dbscan_params(features, eps_range=(0.05, 0.2, 0.05), min_samples_range=(3, 12)):\n",
    "    \"\"\"\n",
    "    Encuentra los parámetros óptimos para DBSCAN (eps y min_samples) basados en el índice de silueta.\n",
    "\n",
    "    Parámetros:\n",
    "    - features: Matriz de características para clustering.\n",
    "    - eps_range: Tupla con rango de valores de eps (inicio, fin, paso).\n",
    "    - min_samples_range: Tupla con valores de min_samples (inicio, fin).\n",
    "\n",
    "    Retorna:\n",
    "    - Mejor combinación de (eps, min_samples) basada en el índice de silueta.\n",
    "    \"\"\"\n",
    "\n",
    "    # Paso 1: Gráfica de distancia de vecinos para estimación inicial de `eps`\n",
    "    neighbors = NearestNeighbors(n_neighbors=2)\n",
    "    neighbors_fit = neighbors.fit(features)\n",
    "    distances, _ = neighbors_fit.kneighbors(features)\n",
    "\n",
    "    # Paso 2: Pruebas de diferentes combinaciones de eps y min_samples\n",
    "    eps_values = np.arange(*eps_range)\n",
    "    min_samples_values = np.arange(*min_samples_range)\n",
    "    dbscan_params = list(product(eps_values, min_samples_values))\n",
    "    \n",
    "    best_params = (None, None)\n",
    "    best_sil_score = -1  # Inicializamos con un valor muy bajo\n",
    "\n",
    "    # Almacenamos métricas para análisis adicional\n",
    "    results = {\n",
    "        'Eps': [],\n",
    "        'Min_samples': [],\n",
    "        'Silhouette Score': [],\n",
    "        'Clusters': []\n",
    "    }\n",
    "\n",
    "    for eps, min_samples in dbscan_params:\n",
    "        db = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "        labels = db.fit_predict(features)\n",
    "\n",
    "        # Solo evaluamos si hay más de un cluster\n",
    "        if len(set(labels)) > 1:\n",
    "            try:\n",
    "                sil_score = silhouette_score(features, labels)\n",
    "            except ValueError:\n",
    "                sil_score = 0  # Si no se puede calcular, asignamos 0\n",
    "        else:\n",
    "            sil_score = 0\n",
    "\n",
    "        # Guardamos resultados en el diccionario\n",
    "        results['Eps'].append(eps)\n",
    "        results['Min_samples'].append(min_samples)\n",
    "        results['Silhouette Score'].append(sil_score)\n",
    "        results['Clusters'].append(len(set(labels)))\n",
    "\n",
    "        # Actualizar los mejores parámetros si encontramos un mejor índice de silueta\n",
    "        if sil_score > best_sil_score:\n",
    "            best_sil_score = sil_score\n",
    "            best_params = (eps, min_samples)\n",
    "\n",
    "    # Convertimos resultados en DataFrame para análisis\n",
    "    df_results = pd.DataFrame(results)\n",
    "\n",
    "    # Resultados de pivot para visualización opcional\n",
    "    pivot_sil_score = pd.pivot_table(df_results, values='Silhouette Score', columns='Eps', index='Min_samples')\n",
    "    pivot_clusters = pd.pivot_table(df_results, values='Clusters', columns='Eps', index='Min_samples')\n",
    "\n",
    "    return best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "348ffc26-db16-4aab-beaf-722293074f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_clusters_hierarchical(features, method='ward', last_n=10):\n",
    "    \"\"\"\n",
    "    Calcula el número óptimo de clusters para clustering jerárquico usando la aceleración en la linkage matrix.\n",
    "\n",
    "    Parámetros:\n",
    "    - features: Matriz de características para clustering.\n",
    "    - method: Método de linkage. Por defecto es 'ward'.\n",
    "    - last_n: Número de fusiones a considerar para calcular el número óptimo de clusters. Por defecto es 10.\n",
    "\n",
    "    Retorna:\n",
    "    - Número óptimo de clusters.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calcular la linkage matrix\n",
    "    mergings = linkage(features, method=method)\n",
    "\n",
    "    # Obtener las alturas de los últimos 'last_n' clusters\n",
    "    last = mergings[-last_n:, 2]\n",
    "    last_rev = last[::-1]\n",
    "\n",
    "    # Calcular la aceleración (segunda derivada)\n",
    "    acceleration = np.diff(last, 2)  # Segunda derivada de las alturas\n",
    "    acceleration_rev = acceleration[::-1]\n",
    "\n",
    "    # Encontrar el número óptimo de clusters\n",
    "    optimal_k = acceleration_rev.argmax() + 2  # +2 porque se pierde una posición en cada derivada\n",
    "\n",
    "    return optimal_k\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97c38af-17dc-448b-b2ec-efc903a8326e",
   "metadata": {},
   "source": [
    "## carga de datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ed7e210-0020-46ea-ab6a-711737080ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path=data_dir(\"interim\",\"estadisticas_edificios.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fbc2227-45f3-45e6-9af0-713099eeb0da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type_building</th>\n",
       "      <th>var1_mean</th>\n",
       "      <th>var1_std_dev</th>\n",
       "      <th>var2_mean</th>\n",
       "      <th>var2_std_dev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RefBldgFullServiceRestaurantNew2004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.226848</td>\n",
       "      <td>19.4245</td>\n",
       "      <td>7.265027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RefBldgFullServiceRestaurantNew2004</td>\n",
       "      <td>0.001580</td>\n",
       "      <td>6.596764</td>\n",
       "      <td>19.4245</td>\n",
       "      <td>7.265027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RefBldgFullServiceRestaurantNew2004</td>\n",
       "      <td>0.002568</td>\n",
       "      <td>7.146033</td>\n",
       "      <td>19.4245</td>\n",
       "      <td>7.265027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RefBldgFullServiceRestaurantNew2004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.688730</td>\n",
       "      <td>19.4245</td>\n",
       "      <td>7.265027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RefBldgFullServiceRestaurantNew2004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.797245</td>\n",
       "      <td>19.4245</td>\n",
       "      <td>7.265027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         type_building  var1_mean  var1_std_dev  var2_mean  \\\n",
       "0  RefBldgFullServiceRestaurantNew2004   0.000000      6.226848    19.4245   \n",
       "1  RefBldgFullServiceRestaurantNew2004   0.001580      6.596764    19.4245   \n",
       "2  RefBldgFullServiceRestaurantNew2004   0.002568      7.146033    19.4245   \n",
       "3  RefBldgFullServiceRestaurantNew2004   0.000000      4.688730    19.4245   \n",
       "4  RefBldgFullServiceRestaurantNew2004   0.000000      4.797245    19.4245   \n",
       "\n",
       "   var2_std_dev  \n",
       "0      7.265027  \n",
       "1      7.265027  \n",
       "2      7.265027  \n",
       "3      7.265027  \n",
       "4      7.265027  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(file_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb325e1-5434-49c9-b35e-897155282456",
   "metadata": {},
   "source": [
    "## CLUSTERING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9707de78-0a1a-4e5b-aa8e-6f2bc2062044",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clustered=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c489fc34-d1f3-441d-bae5-aa27c2f0cd7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.2), np.int64(3))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params=optimal_dbscan_params(X, eps_range=(0.05, 0.2, 0.05), min_samples_range=(3, 12))\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71881e9c-42f3-4a66-a503-8c92333ab7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type_building</th>\n",
       "      <th>var1_mean</th>\n",
       "      <th>var1_std_dev</th>\n",
       "      <th>var2_mean</th>\n",
       "      <th>var2_std_dev</th>\n",
       "      <th>Cluster_KMeans</th>\n",
       "      <th>Cluster_DBSCAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RefBldgFullServiceRestaurantNew2004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.226848</td>\n",
       "      <td>19.4245</td>\n",
       "      <td>7.265027</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RefBldgFullServiceRestaurantNew2004</td>\n",
       "      <td>0.001580</td>\n",
       "      <td>6.596764</td>\n",
       "      <td>19.4245</td>\n",
       "      <td>7.265027</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RefBldgFullServiceRestaurantNew2004</td>\n",
       "      <td>0.002568</td>\n",
       "      <td>7.146033</td>\n",
       "      <td>19.4245</td>\n",
       "      <td>7.265027</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RefBldgFullServiceRestaurantNew2004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.688730</td>\n",
       "      <td>19.4245</td>\n",
       "      <td>7.265027</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RefBldgFullServiceRestaurantNew2004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.797245</td>\n",
       "      <td>19.4245</td>\n",
       "      <td>7.265027</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         type_building  var1_mean  var1_std_dev  var2_mean  \\\n",
       "0  RefBldgFullServiceRestaurantNew2004   0.000000      6.226848    19.4245   \n",
       "1  RefBldgFullServiceRestaurantNew2004   0.001580      6.596764    19.4245   \n",
       "2  RefBldgFullServiceRestaurantNew2004   0.002568      7.146033    19.4245   \n",
       "3  RefBldgFullServiceRestaurantNew2004   0.000000      4.688730    19.4245   \n",
       "4  RefBldgFullServiceRestaurantNew2004   0.000000      4.797245    19.4245   \n",
       "\n",
       "   var2_std_dev  Cluster_KMeans  Cluster_DBSCAN  \n",
       "0      7.265027               0               0  \n",
       "1      7.265027               0               0  \n",
       "2      7.265027               0               0  \n",
       "3      7.265027               0               0  \n",
       "4      7.265027               0               0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicar DBSCAN\n",
    "dbscan = DBSCAN(eps=params[0], min_samples=params[1])\n",
    "clusters_dbscan = dbscan.fit_predict(X)\n",
    "\n",
    "# Agregar los clusters al DataFrame para análisis posterior\n",
    "data_clustered['Cluster_DBSCAN'] = clusters_dbscan\n",
    "# Mostrar los primeros registros con los clusters asignados por DBSCAN\n",
    "data_clustered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7595d90-325e-40af-b482-b5dc78c726eb",
   "metadata": {},
   "source": [
    "**Silueta**\n",
    "El coeficiente de silueta mide cuán similares son los objetos dentro de un mismo cluster comparados con objetos de otros clusters. Va de -1 a 1, donde valores cercanos a 1 indican buenos clusters, cercanos a 0 indican clusters solapados y valores negativos indican asignaciones incorrectas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1dc60423-4559-4ad4-9753-4d7221bc9cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6378114591428399)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcular el silhouette score para evaluar la calidad de los clusters, excluyendo los puntos ruidosos\n",
    "if len(set(clusters_dbscan)) > 1:\n",
    "    silhouette_dbscan = silhouette_score(X, clusters_dbscan)\n",
    "else:\n",
    "    silhouette_dbscan = -1  # Silhouette score no es aplicable si hay un solo cluster\n",
    "silhouette_dbscan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fd3d0c-11aa-4abe-bd87-dff6f74f68bb",
   "metadata": {},
   "source": [
    "**Índice de Davies-Bouldin**\n",
    "Mide la compactación de los clusters y la separación entre ellos. Un valor más bajo indica una mejor formación de clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5dee5787-95f3-492d-a32a-05bb6f513151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8368992004306053)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcular el índice de Davies-Bouldin\n",
    "davies_bouldin_dbscan= davies_bouldin_score(X, clusters_dbscan)\n",
    "davies_bouldin_dbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6bfee1f-da63-416e-8ad1-210de8916763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_analysis(data, max_k=10, eps_range=(0.05, 0.2, 0.05), min_samples_range=(3, 12)):\n",
    "    # Estandarización de los datos\n",
    "    numeric_columns = data.select_dtypes(include=['float64']).columns\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(data[numeric_columns])\n",
    "    X = pd.DataFrame(data_scaled, columns=numeric_columns)\n",
    "    \n",
    "    # DataFrame para almacenar métricas de cada modelo\n",
    "    metrics = pd.DataFrame(columns=[\"Model\", \"Silhouette Score\", \"Davies-Bouldin Index\"])\n",
    "\n",
    "    # K-Means Clustering\n",
    "    optimal_k_kmeans = optimal_k_selection(X, max_k=max_k)\n",
    "    kmeans = KMeans(n_clusters=optimal_k_kmeans, random_state=42)\n",
    "    clusters_kmeans = kmeans.fit_predict(X)\n",
    "    silhouette_kmeans = silhouette_score(X, clusters_kmeans)\n",
    "    davies_bouldin_kmeans = davies_bouldin_score(X, clusters_kmeans)\n",
    "    \n",
    "    # Añadir métricas de K-Means al DataFrame\n",
    "    metrics = pd.concat([metrics, pd.DataFrame({\n",
    "        \"Model\": [\"K-Means\"],\n",
    "        \"Silhouette Score\": [silhouette_kmeans],\n",
    "        \"Davies-Bouldin Index\": [davies_bouldin_kmeans]\n",
    "    })], ignore_index=True)\n",
    "\n",
    "    # DBSCAN Clustering\n",
    "    eps_min_samples = optimal_dbscan_params(X, eps_range=eps_range, min_samples_range=min_samples_range)\n",
    "    dbscan = DBSCAN(eps=eps_min_samples[0], min_samples=eps_min_samples[1])\n",
    "    clusters_dbscan = dbscan.fit_predict(X)\n",
    "\n",
    "    # Calculamos las métricas solo si hay más de un cluster\n",
    "    if len(set(clusters_dbscan)) > 1:\n",
    "        silhouette_dbscan = silhouette_score(X, clusters_dbscan)\n",
    "    else:\n",
    "        silhouette_dbscan = -1  # Silhouette score no es aplicable si hay un solo cluster\n",
    "    davies_bouldin_dbscan = davies_bouldin_score(X, clusters_dbscan)\n",
    "\n",
    "    # Añadir métricas de DBSCAN al DataFrame\n",
    "    metrics = pd.concat([metrics, pd.DataFrame({\n",
    "        \"Model\": [\"DBSCAN\"],\n",
    "        \"Silhouette Score\": [silhouette_dbscan],\n",
    "        \"Davies-Bouldin Index\": [davies_bouldin_dbscan]\n",
    "    })], ignore_index=True)\n",
    "\n",
    "    # Clustering Jerárquico\n",
    "    optimal_k_hierarchical = optimal_clusters_hierarchical(X, method='ward', last_n=10)\n",
    "    hierarchical = AgglomerativeClustering(n_clusters=optimal_k_hierarchical)\n",
    "    clusters_hierarchical = hierarchical.fit_predict(X)\n",
    "    silhouette_hierarchical = silhouette_score(X, clusters_hierarchical)\n",
    "    davies_bouldin_hierarchical = davies_bouldin_score(X, clusters_hierarchical)\n",
    "\n",
    "    # Añadir métricas de clustering jerárquico al DataFrame\n",
    "    metrics = pd.concat([metrics, pd.DataFrame({\n",
    "        \"Model\": [\"Hierarchical\"],\n",
    "        \"Silhouette Score\": [silhouette_hierarchical],\n",
    "        \"Davies-Bouldin Index\": [davies_bouldin_hierarchical]\n",
    "    })], ignore_index=True)\n",
    "\n",
    "    # Normalización de las métricas para la selección del mejor modelo\n",
    "    metrics[\"Silhouette Score Norm\"] = (metrics[\"Silhouette Score\"] - metrics[\"Silhouette Score\"].min()) / (metrics[\"Silhouette Score\"].max() - metrics[\"Silhouette Score\"].min())\n",
    "    metrics[\"Davies-Bouldin Index Norm\"] = (metrics[\"Davies-Bouldin Index\"].max() - metrics[\"Davies-Bouldin Index\"]) / (metrics[\"Davies-Bouldin Index\"].max() - metrics[\"Davies-Bouldin Index\"].min())\n",
    "    \n",
    "    # Cálculo de la puntuación combinada (promedio de ambas métricas normalizadas)\n",
    "    metrics[\"Combined Score\"] = metrics[[\"Silhouette Score Norm\", \"Davies-Bouldin Index Norm\"]].mean(axis=1)\n",
    "\n",
    "    # Selección del mejor modelo según la puntuación combinada\n",
    "    best_model = metrics.loc[metrics[\"Combined Score\"].idxmax()]\n",
    "\n",
    "    return metrics, best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "52cbff81-4618-49d8-9662-5e6a37850564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS TUF\\.conda\\envs\\energy_consumption_architecture\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS TUF\\.conda\\envs\\energy_consumption_architecture\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS TUF\\.conda\\envs\\energy_consumption_architecture\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS TUF\\.conda\\envs\\energy_consumption_architecture\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS TUF\\.conda\\envs\\energy_consumption_architecture\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS TUF\\.conda\\envs\\energy_consumption_architecture\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS TUF\\.conda\\envs\\energy_consumption_architecture\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS TUF\\.conda\\envs\\energy_consumption_architecture\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS TUF\\.conda\\envs\\energy_consumption_architecture\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS TUF\\.conda\\envs\\energy_consumption_architecture\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS TUF\\AppData\\Local\\Temp\\ipykernel_56136\\2266543390.py:19: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  metrics = pd.concat([metrics, pd.DataFrame({\n"
     ]
    }
   ],
   "source": [
    "metrics,best_models=clustering_analysis(data, max_k=10, eps_range=(0.05, 0.2, 0.05), min_samples_range=(3, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0675a29f-5f8c-4f51-ba81-76e27cfa8160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Silhouette Score</th>\n",
       "      <th>Davies-Bouldin Index</th>\n",
       "      <th>Silhouette Score Norm</th>\n",
       "      <th>Davies-Bouldin Index Norm</th>\n",
       "      <th>Combined Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K-Means</td>\n",
       "      <td>0.832731</td>\n",
       "      <td>0.171948</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DBSCAN</td>\n",
       "      <td>0.637811</td>\n",
       "      <td>0.836899</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hierarchical</td>\n",
       "      <td>0.762659</td>\n",
       "      <td>0.699451</td>\n",
       "      <td>0.640507</td>\n",
       "      <td>0.206704</td>\n",
       "      <td>0.423605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model  Silhouette Score  Davies-Bouldin Index  \\\n",
       "0       K-Means          0.832731              0.171948   \n",
       "1        DBSCAN          0.637811              0.836899   \n",
       "2  Hierarchical          0.762659              0.699451   \n",
       "\n",
       "   Silhouette Score Norm  Davies-Bouldin Index Norm  Combined Score  \n",
       "0               1.000000                   1.000000        1.000000  \n",
       "1               0.000000                   0.000000        0.000000  \n",
       "2               0.640507                   0.206704        0.423605  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a7aa48f1-4977-4f6b-8c8c-adcc6c01ba65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model                         K-Means\n",
       "Silhouette Score             0.832731\n",
       "Davies-Bouldin Index         0.171948\n",
       "Silhouette Score Norm             1.0\n",
       "Davies-Bouldin Index Norm         1.0\n",
       "Combined Score                    1.0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b2f03a-b4b3-4986-8c18-755c6db65d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
